{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.3"
    },
    "colab": {
      "name": "01_11.ipynb",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mohanrajmit/NLP/blob/master/ML/Data_cleaning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MGbHZHlm1RT5",
        "colab_type": "text"
      },
      "source": [
        "# NLP Basics: Implementing a pipeline to clean text"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G2omGVzk1RT8",
        "colab_type": "text"
      },
      "source": [
        "### Pre-processing text data\n",
        "\n",
        "Cleaning up the text data is necessary to highlight attributes that you're going to want your machine learning system to pick up on. Cleaning (or pre-processing) the data typically consists of a number of steps:\n",
        "1. **Remove punctuation**\n",
        "2. **Tokenization**\n",
        "3. **Remove stopwords**\n",
        "4. Lemmatize/Stem\n",
        "\n",
        "The first three steps are covered in this chapter as they're implemented in pretty much any text cleaning pipeline. Lemmatizing and stemming are covered in the next chapter as they're helpful but not critical."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-pLh4vg7Jm53",
        "colab_type": "code",
        "outputId": "0ec59557-38d6-46c5-ad8c-91d0f55fd803",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "!git clone https://github.com/mohanrajmit/ML-training.git"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'ML-training'...\n",
            "remote: Enumerating objects: 35, done.\u001b[K\n",
            "remote: Counting objects: 100% (35/35), done.\u001b[K\n",
            "remote: Compressing objects: 100% (35/35), done.\u001b[K\n",
            "remote: Total 38 (delta 16), reused 0 (delta 0), pack-reused 3\u001b[K\n",
            "Unpacking objects: 100% (38/38), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0gbNa4xv1RT9",
        "colab_type": "code",
        "outputId": "4b877f96-14d7-4184-a624-a58afc50ac37",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "import pandas as pd\n",
        "pd.set_option('display.max_colwidth', 100)\n",
        "\n",
        "data = pd.read_csv(\"/content/ML-training/SMSSpamCollection.tsv\", sep='\\t', header=None)\n",
        "data.columns = ['label', 'body_text']\n",
        "\n",
        "data.head()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>body_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ham</td>\n",
              "      <td>I've been searching for the right words to thank you for this breather. I promise i wont take yo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>spam</td>\n",
              "      <td>Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005. Text FA to 87121 to receive ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>ham</td>\n",
              "      <td>Nah I don't think he goes to usf, he lives around here though</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ham</td>\n",
              "      <td>Even my brother is not like to speak with me. They treat me like aids patent.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ham</td>\n",
              "      <td>I HAVE A DATE ON SUNDAY WITH WILL!!</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  label                                                                                            body_text\n",
              "0   ham  I've been searching for the right words to thank you for this breather. I promise i wont take yo...\n",
              "1  spam  Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005. Text FA to 87121 to receive ...\n",
              "2   ham                                        Nah I don't think he goes to usf, he lives around here though\n",
              "3   ham                        Even my brother is not like to speak with me. They treat me like aids patent.\n",
              "4   ham                                                                  I HAVE A DATE ON SUNDAY WITH WILL!!"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r7_ktx5E1RUC",
        "colab_type": "code",
        "outputId": "b13917af-a61d-498e-d296-4dfbc5715941",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "# What does the cleaned version look like?\n",
        "data_cleaned = pd.read_csv(\"/content/ML-training/SMSSpamCollection_cleaned.tsv\", sep='\\t')\n",
        "data_cleaned.head()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>body_text</th>\n",
              "      <th>body_text_nostop</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ham</td>\n",
              "      <td>I've been searching for the right words to thank you for this breather. I promise i wont take yo...</td>\n",
              "      <td>['ive', 'searching', 'right', 'words', 'thank', 'breather', 'promise', 'wont', 'take', 'help', '...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>spam</td>\n",
              "      <td>Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005. Text FA to 87121 to receive ...</td>\n",
              "      <td>['free', 'entry', '2', 'wkly', 'comp', 'win', 'fa', 'cup', 'final', 'tkts', '21st', 'may', '2005...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>ham</td>\n",
              "      <td>Nah I don't think he goes to usf, he lives around here though</td>\n",
              "      <td>['nah', 'dont', 'think', 'goes', 'usf', 'lives', 'around', 'though']</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ham</td>\n",
              "      <td>Even my brother is not like to speak with me. They treat me like aids patent.</td>\n",
              "      <td>['even', 'brother', 'like', 'speak', 'treat', 'like', 'aids', 'patent']</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ham</td>\n",
              "      <td>I HAVE A DATE ON SUNDAY WITH WILL!!</td>\n",
              "      <td>['date', 'sunday']</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  label  ...                                                                                     body_text_nostop\n",
              "0   ham  ...  ['ive', 'searching', 'right', 'words', 'thank', 'breather', 'promise', 'wont', 'take', 'help', '...\n",
              "1  spam  ...  ['free', 'entry', '2', 'wkly', 'comp', 'win', 'fa', 'cup', 'final', 'tkts', '21st', 'may', '2005...\n",
              "2   ham  ...                                 ['nah', 'dont', 'think', 'goes', 'usf', 'lives', 'around', 'though']\n",
              "3   ham  ...                              ['even', 'brother', 'like', 'speak', 'treat', 'like', 'aids', 'patent']\n",
              "4   ham  ...                                                                                   ['date', 'sunday']\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zhEMkqbj1RUG",
        "colab_type": "text"
      },
      "source": [
        "### Remove punctuation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xiy9xiqk1RUI",
        "colab_type": "code",
        "outputId": "516136e3-51e9-46f8-9ac2-dafa1ca7657f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import string\n",
        "string.punctuation"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DIvN2l5u1RUM",
        "colab_type": "code",
        "outputId": "4826a0c8-d8f9-433a-f778-9b816e7f4661",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "\"I like NLP.\" == \"I like NLP\""
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UKHBC4yB1RUP",
        "colab_type": "code",
        "outputId": "3ea7711f-41ae-47dc-addf-8b84e1f776a0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "def remove_punct(text):\n",
        "    text_nopunct = \"\".join([char for char in text if char not in string.punctuation])\n",
        "    return text_nopunct\n",
        "\n",
        "data['body_text_clean'] = data['body_text'].apply(lambda x: remove_punct(x))\n",
        "\n",
        "data.head()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>body_text</th>\n",
              "      <th>body_text_clean</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ham</td>\n",
              "      <td>I've been searching for the right words to thank you for this breather. I promise i wont take yo...</td>\n",
              "      <td>Ive been searching for the right words to thank you for this breather I promise i wont take your...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>spam</td>\n",
              "      <td>Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005. Text FA to 87121 to receive ...</td>\n",
              "      <td>Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005 Text FA to 87121 to receive e...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>ham</td>\n",
              "      <td>Nah I don't think he goes to usf, he lives around here though</td>\n",
              "      <td>Nah I dont think he goes to usf he lives around here though</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ham</td>\n",
              "      <td>Even my brother is not like to speak with me. They treat me like aids patent.</td>\n",
              "      <td>Even my brother is not like to speak with me They treat me like aids patent</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ham</td>\n",
              "      <td>I HAVE A DATE ON SUNDAY WITH WILL!!</td>\n",
              "      <td>I HAVE A DATE ON SUNDAY WITH WILL</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  label  ...                                                                                      body_text_clean\n",
              "0   ham  ...  Ive been searching for the right words to thank you for this breather I promise i wont take your...\n",
              "1  spam  ...  Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005 Text FA to 87121 to receive e...\n",
              "2   ham  ...                                          Nah I dont think he goes to usf he lives around here though\n",
              "3   ham  ...                          Even my brother is not like to speak with me They treat me like aids patent\n",
              "4   ham  ...                                                                    I HAVE A DATE ON SUNDAY WITH WILL\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vibo4yoE1RUS",
        "colab_type": "text"
      },
      "source": [
        "### Tokenization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3BcNfYE21RUT",
        "colab_type": "code",
        "outputId": "75668148-44dd-4da3-ab04-20025f359f27",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        }
      },
      "source": [
        "import re\n",
        "\n",
        "def tokenize(text):\n",
        "    tokens = re.split('\\W+', text)\n",
        "    return tokens\n",
        "\n",
        "data['body_text_tokenized'] = data['body_text_clean'].apply(lambda x: tokenize(x.lower()))\n",
        "\n",
        "data.head()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>body_text</th>\n",
              "      <th>body_text_clean</th>\n",
              "      <th>body_text_tokenized</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ham</td>\n",
              "      <td>I've been searching for the right words to thank you for this breather. I promise i wont take yo...</td>\n",
              "      <td>Ive been searching for the right words to thank you for this breather I promise i wont take your...</td>\n",
              "      <td>[ive, been, searching, for, the, right, words, to, thank, you, for, this, breather, i, promise, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>spam</td>\n",
              "      <td>Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005. Text FA to 87121 to receive ...</td>\n",
              "      <td>Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005 Text FA to 87121 to receive e...</td>\n",
              "      <td>[free, entry, in, 2, a, wkly, comp, to, win, fa, cup, final, tkts, 21st, may, 2005, text, fa, to...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>ham</td>\n",
              "      <td>Nah I don't think he goes to usf, he lives around here though</td>\n",
              "      <td>Nah I dont think he goes to usf he lives around here though</td>\n",
              "      <td>[nah, i, dont, think, he, goes, to, usf, he, lives, around, here, though]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ham</td>\n",
              "      <td>Even my brother is not like to speak with me. They treat me like aids patent.</td>\n",
              "      <td>Even my brother is not like to speak with me They treat me like aids patent</td>\n",
              "      <td>[even, my, brother, is, not, like, to, speak, with, me, they, treat, me, like, aids, patent]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ham</td>\n",
              "      <td>I HAVE A DATE ON SUNDAY WITH WILL!!</td>\n",
              "      <td>I HAVE A DATE ON SUNDAY WITH WILL</td>\n",
              "      <td>[i, have, a, date, on, sunday, with, will]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  label  ...                                                                                  body_text_tokenized\n",
              "0   ham  ...  [ive, been, searching, for, the, right, words, to, thank, you, for, this, breather, i, promise, ...\n",
              "1  spam  ...  [free, entry, in, 2, a, wkly, comp, to, win, fa, cup, final, tkts, 21st, may, 2005, text, fa, to...\n",
              "2   ham  ...                            [nah, i, dont, think, he, goes, to, usf, he, lives, around, here, though]\n",
              "3   ham  ...         [even, my, brother, is, not, like, to, speak, with, me, they, treat, me, like, aids, patent]\n",
              "4   ham  ...                                                           [i, have, a, date, on, sunday, with, will]\n",
              "\n",
              "[5 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ASBn7-Xe1RUX",
        "colab_type": "code",
        "outputId": "57f8f112-66bc-499e-ee96-7a7bf25515c5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "'NLP' == 'nlp'"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NgZfHTEM1RUa",
        "colab_type": "text"
      },
      "source": [
        "### Remove stopwords"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NNKVCfYv1RUb",
        "colab_type": "code",
        "outputId": "4642938c-c8f9-46a4-9675-8b70def11267",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        }
      },
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "\n",
        "stopword = nltk.corpus.stopwords.words('english')\n",
        "print(stopword)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1lNbvw9O1RUh",
        "colab_type": "code",
        "outputId": "0b18e0b4-d3dc-4439-8045-2b785167c94f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        }
      },
      "source": [
        "def remove_stopwords(tokenized_list):\n",
        "    text = [word for word in tokenized_list if word not in stopword]\n",
        "    return text\n",
        "\n",
        "data['body_text_nostop'] = data['body_text_tokenized'].apply(lambda x: remove_stopwords(x))\n",
        "\n",
        "data.head()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>body_text</th>\n",
              "      <th>body_text_clean</th>\n",
              "      <th>body_text_tokenized</th>\n",
              "      <th>body_text_nostop</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ham</td>\n",
              "      <td>I've been searching for the right words to thank you for this breather. I promise i wont take yo...</td>\n",
              "      <td>Ive been searching for the right words to thank you for this breather I promise i wont take your...</td>\n",
              "      <td>[ive, been, searching, for, the, right, words, to, thank, you, for, this, breather, i, promise, ...</td>\n",
              "      <td>[ive, searching, right, words, thank, breather, promise, wont, take, help, granted, fulfil, prom...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>spam</td>\n",
              "      <td>Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005. Text FA to 87121 to receive ...</td>\n",
              "      <td>Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005 Text FA to 87121 to receive e...</td>\n",
              "      <td>[free, entry, in, 2, a, wkly, comp, to, win, fa, cup, final, tkts, 21st, may, 2005, text, fa, to...</td>\n",
              "      <td>[free, entry, 2, wkly, comp, win, fa, cup, final, tkts, 21st, may, 2005, text, fa, 87121, receiv...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>ham</td>\n",
              "      <td>Nah I don't think he goes to usf, he lives around here though</td>\n",
              "      <td>Nah I dont think he goes to usf he lives around here though</td>\n",
              "      <td>[nah, i, dont, think, he, goes, to, usf, he, lives, around, here, though]</td>\n",
              "      <td>[nah, dont, think, goes, usf, lives, around, though]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ham</td>\n",
              "      <td>Even my brother is not like to speak with me. They treat me like aids patent.</td>\n",
              "      <td>Even my brother is not like to speak with me They treat me like aids patent</td>\n",
              "      <td>[even, my, brother, is, not, like, to, speak, with, me, they, treat, me, like, aids, patent]</td>\n",
              "      <td>[even, brother, like, speak, treat, like, aids, patent]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ham</td>\n",
              "      <td>I HAVE A DATE ON SUNDAY WITH WILL!!</td>\n",
              "      <td>I HAVE A DATE ON SUNDAY WITH WILL</td>\n",
              "      <td>[i, have, a, date, on, sunday, with, will]</td>\n",
              "      <td>[date, sunday]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  label  ...                                                                                     body_text_nostop\n",
              "0   ham  ...  [ive, searching, right, words, thank, breather, promise, wont, take, help, granted, fulfil, prom...\n",
              "1  spam  ...  [free, entry, 2, wkly, comp, win, fa, cup, final, tkts, 21st, may, 2005, text, fa, 87121, receiv...\n",
              "2   ham  ...                                                 [nah, dont, think, goes, usf, lives, around, though]\n",
              "3   ham  ...                                              [even, brother, like, speak, treat, like, aids, patent]\n",
              "4   ham  ...                                                                                       [date, sunday]\n",
              "\n",
              "[5 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "knmNiWt91RUk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}